{"cells":[{"cell_type":"code","execution_count":null,"id":"5fa21d44","metadata":{"id":"5fa21d44"},"outputs":[],"source":["# Copyright (c) Meta Platforms, Inc. and affiliates."]},{"cell_type":"code","execution_count":null,"id":"072e25b8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":42},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1725542336381,"user":{"displayName":"Virginia Coletta","userId":"03269993022852155364"},"user_tz":-120},"id":"072e25b8","outputId":"6d1c0212-1d63-43a4-dc21-22858b012e5b"},"outputs":[{"data":{"text/html":["\n","<a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["#Importazione del file HTML\n","from IPython.display import display, HTML\n","display(HTML(\n","\"\"\"\n","<a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n","\"\"\"\n","))"]},{"cell_type":"markdown","id":"c0b71431","metadata":{"id":"c0b71431"},"source":["## Environment Set-up"]},{"cell_type":"markdown","id":"47e5a78f","metadata":{"id":"47e5a78f"},"source":["If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."]},{"cell_type":"code","execution_count":null,"id":"4fe300fb","metadata":{"id":"4fe300fb"},"outputs":[],"source":["using_colab = True"]},{"cell_type":"code","execution_count":null,"id":"0685a2f5","metadata":{"id":"0685a2f5"},"outputs":[],"source":["#Ambiente\n","\n","if using_colab:\n","    import torch\n","    import torchvision\n","    # print(\"PyTorch version:\", torch.__version__)\n","    # print(\"Torchvision version:\", torchvision.__version__)\n","    # print(\"CUDA is available:\", torch.cuda.is_available())\n","    import sys\n","    !{sys.executable} -m pip install opencv-python matplotlib\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n","    !pip install rasterio\n","\n","    !mkdir images\n","\n","    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"]},{"cell_type":"code","execution_count":null,"id":"560725a2","metadata":{"id":"560725a2"},"outputs":[],"source":["from tensorflow.python.client import device_lib\n","!nvidia-smi\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import rasterio"]},{"cell_type":"code","execution_count":null,"id":"74b6e5f0","metadata":{"id":"74b6e5f0"},"outputs":[],"source":["def show_anns(anns):\n","    if len(anns) == 0:\n","        return\n","    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n","    ax = plt.gca()\n","    ax.set_autoscale_on(False)\n","    polygons = []\n","    color = []\n","    for ann in sorted_anns:\n","        m = ann['segmentation']\n","        img = np.ones((m.shape[0], m.shape[1], 3))\n","        color_mask = np.random.random((1, 3)).tolist()[0]\n","        for i in range(3):\n","            img[:,:,i] = color_mask[i]\n","        ax.imshow(np.dstack((img, m*0.35)))"]},{"cell_type":"markdown","id":"M67jQRf-3xXg","metadata":{"id":"M67jQRf-3xXg"},"source":["## Image Processing\n"]},{"cell_type":"code","execution_count":null,"id":"xHGORE1EC6o0","metadata":{"id":"xHGORE1EC6o0"},"outputs":[],"source":["def stretch_contrast(image):\n","    # Calculate the 2nd and 98th percentiles for each band\n","    p2 = np.percentile(image, 2, axis=(0, 1))\n","    p98 = np.percentile(image, 98, axis=(0, 1))\n","\n","    # Stretch contrast for each band\n","    stretched_image = np.zeros_like(image, dtype=np.uint8)\n","    for i in range(image.shape[2]):\n","        stretched_image[:, :, i] = np.clip((image[:, :, i] - p2[i]) / (p98[i] - p2[i]) * 255, 0, 255)\n","\n","    return stretched_image"]},{"cell_type":"code","execution_count":null,"id":"ad354922","metadata":{"id":"ad354922"},"outputs":[],"source":["images_path = os.listdir(/path/to/image/collection)\n","path = /path/to/image/collection\n","\n","images = []\n","for image_filename in images_path:\n","  image = cv2.imread(os.path.join(path,image_filename), cv2.IMREAD_UNCHANGED)\n","  image = stretch_contrast(image)\n","  images.append(image)"]},{"cell_type":"code","execution_count":null,"id":"iPrTxRSJpMhI","metadata":{"id":"iPrTxRSJpMhI"},"outputs":[],"source":["# Reference raster of the area\n","\n","path = /path/to/reference/raster\n","with rasterio.open(path) as src:\n","    raster_reference = src.read(1)"]},{"cell_type":"markdown","id":"g9EXPR7SfQ1K","metadata":{"id":"g9EXPR7SfQ1K"},"source":["# Mask generation from seeds"]},{"cell_type":"code","execution_count":null,"id":"1848a108","metadata":{"id":"1848a108"},"outputs":[],"source":["import sys\n","sys.path.append(\"..\")\n","from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n","\n","sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n","model_type = \"vit_h\"\n","device = 'cuda'\n","\n","sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n","sam.to(device=device)\n","\n","mask_generator = SamAutomaticMaskGenerator(sam)\n"]},{"cell_type":"code","execution_count":null,"id":"2q0IQfq2eSXs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3042,"status":"ok","timestamp":1725542410919,"user":{"displayName":"Virginia Coletta","userId":"03269993022852155364"},"user_tz":-120},"id":"2q0IQfq2eSXs","outputId":"352dc61d-4901-4ab3-a902-00a744bc97e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/516.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.3/516.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -qq ipympl\n","from google.colab import output\n","output.enable_custom_widget_manager()\n","%matplotlib ipympl"]},{"cell_type":"code","execution_count":null,"id":"zAtZ8eyHqgzq","metadata":{"id":"zAtZ8eyHqgzq"},"outputs":[],"source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","import cv2\n","from PIL import Image\n","\n","def show_mask(mask, ax, random_color=False):\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n","    else:\n","        color = np.array([30/255, 144/255, 255/255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","    ax.imshow(mask_image)\n","\n","def show_points(coords, labels, ax, marker_size=375):\n","    pos_points = coords[labels==1]\n","    neg_points = coords[labels==0]\n","    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)"]},{"cell_type":"markdown","id":"_MLjm669-Z_L","metadata":{"id":"_MLjm669-Z_L"},"source":["### Coordinates to pixel\n","This allows to fix the coordinates of the seed given in input to perform a multitemporal analysis of the results"]},{"cell_type":"code","execution_count":null,"id":"cfemRniT-Bac","metadata":{"id":"cfemRniT-Bac"},"outputs":[],"source":["def coordinates_to_pixel(lon, lat, geotransform):\n","    \"\"\"\n","    Converts geographical coordinates to pixel coordinates within the image using the geotransform parameters.\n","\n","    Parameters:\n","        lon (float): Longitude of the point.\n","        lat (float): Latitude of the point.\n","        geotransform (tuple): Geotransform parameters (affine transformation matrix).\n","\n","    Returns:\n","        Tuple (int, int): Pixel coordinates (x, y).\n","    \"\"\"\n","    # Extract geotransform parameters\n","    origin_x = geotransform[0]\n","    origin_y = geotransform[3]\n","    pixel_width = geotransform[1]\n","    pixel_height = geotransform[5]\n","\n","    # Calculate pixel coordinates\n","    pixel_x = int((lon - origin_x) / pixel_width)\n","    pixel_y = int((lat - origin_y) / pixel_height)\n","\n","    return pixel_x, pixel_y"]},{"cell_type":"code","execution_count":null,"id":"YdxqnFNv-Zd5","metadata":{"id":"YdxqnFNv-Zd5"},"outputs":[],"source":["from osgeo import gdal\n","\n","# Obtain the geotransforms of the image\n","raster_ds = gdal.Open(/path/to/image/)\n","geotransform = raster_ds.GetGeoTransform()\n","print(\"Geotransform parameters:\", geotransform)\n","\n","# Known coordinates\n","lon = 8.91738465504492\n","lat = 44.410415991918875\n","\n","# Convert geographical coordinates to pixel coordinates\n","x, y = coordinates_to_pixel(lon, lat, geotransform)\n","\n","print(\"Pixel coordinates:\", x, y)"]},{"cell_type":"markdown","id":"kdXpxWFzpdp1","metadata":{"id":"kdXpxWFzpdp1"},"source":["## Seed from fixed coordinates"]},{"cell_type":"code","execution_count":null,"id":"VR_S8QflkFSE","metadata":{"id":"VR_S8QflkFSE"},"outputs":[],"source":["def predict_at_pixel(x, y, predictor, ax):\n","    global output_mask\n","    # Prepare input for prediction\n","    input_point = np.array([[x, y]])\n","    input_label = np.array([1])\n","\n","    # Perform prediction for each predictor\n","    masks, scores, logits = predictor.predict(\n","        point_coords=input_point,\n","        point_labels=input_label,\n","        multimask_output=True,\n","    )\n","\n","    # Select the mask with highest score\n","    mask = masks[np.argmax(scores)]\n","\n","    # Show the mask and input point\n","    show_mask(mask, ax, random_color=True)\n","    show_points(input_point, input_label, ax, marker_size=100)\n","\n","    # Append the predicted mask to output_masks list\n","    output_mask = mask\n","    return output_mask"]},{"cell_type":"code","execution_count":null,"id":"3z7lkUf-e6x9","metadata":{"id":"3z7lkUf-e6x9"},"outputs":[],"source":["# Make a prediction for each image at the same point\n","\n","plt.close('all')\n","\n","# Define the subplot grid\n","n_images = len(images)\n","fig, axs = plt.subplots(n_images, figsize=(20, 20))\n","output_masks =[]\n","\n","# Loop through each image\n","for i, (image, ax) in enumerate(zip(images, axs)):\n","    ax = axs[i]\n","    ax.imshow(image)\n","    ax.axis('off')\n","    ax.set_title(f'Image {i}')\n","\n","    # Compute the predicted mask for the current image\n","    predictor = SamPredictor(sam)\n","    predictor.set_image(image)\n","    output_mask = predict_at_pixel(x, y, predictor, ax)\n","    output_masks.append(output_mask)\n","\n","    # Overlay the predicted mask on the current image\n","    #ax.imshow(output_mask, alpha=0.5)  # Assuming only one mask per image\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"ukpUE4rXEwWe","metadata":{"id":"ukpUE4rXEwWe"},"outputs":[],"source":["# Create a list containing the binary masks of the 4 periods\n","\n","output_masks_bianary = []\n","for mask in output_masks:\n","  mask = mask.astype(int)\n","  output_masks_bianary.append(mask)"]},{"cell_type":"code","execution_count":null,"id":"eMUh8Y3Oy042","metadata":{"id":"eMUh8Y3Oy042"},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score, precision_score\n","import numpy as np\n","\n","# Compute metrics for each mask\n","for idx, mask in enumerate(output_masks_bianary):\n","    # Flatten the masks to 1D arrays\n","    mask_flat = mask.flatten()\n","    reference_mask_flat = raster_reference.flatten()\n","\n","    # Compute metrics\n","    f1 = f1_score(reference_mask_flat, mask_flat)\n","    accuracy = accuracy_score(reference_mask_flat, mask_flat)\n","    precision = precision_score(reference_mask_flat, mask_flat)\n","\n","    # Intersection over Union (IoU)\n","    intersection = np.logical_and(raster_reference, mask)\n","    union = np.logical_or(raster_reference, mask)\n","    iou = np.sum(intersection) / np.sum(union)\n","\n","    print(f\"Metrics for mask {idx}:\")\n","    print(f\"F1 Score: {f1}\")\n","    print(f\"Accuracy: {accuracy}\")\n","    print(f\"Precision: {precision}\")\n","    print(f\"IoU: {iou}\")\n","    print()"]},{"cell_type":"markdown","id":"MDLj0W8waNvn","metadata":{"id":"MDLj0W8waNvn"},"source":["## Compute masks based on a grid of points (all over the image)"]},{"cell_type":"code","execution_count":null,"id":"1bwu5DDxLKXk","metadata":{"id":"1bwu5DDxLKXk"},"outputs":[],"source":["def create_grid(image_width, image_height, step_size):\n","    # Calculate number of points in x and y directions\n","    num_points_x = int(np.ceil(image_width / step_size))\n","    num_points_y = int(np.ceil(image_height / step_size))\n","\n","    # Create grid of points\n","    grid_points = []\n","    for i in range(num_points_x):\n","        for j in range(num_points_y):\n","            x = i * step_size\n","            y = j * step_size\n","            grid_points.append((x, y))\n","\n","    return grid_points"]},{"cell_type":"code","execution_count":null,"id":"8dqnsTCVPBQC","metadata":{"id":"8dqnsTCVPBQC"},"outputs":[],"source":["def predict_masks_at_grid_points(images, grid_points):\n","    output_masks = []\n","\n","    for image in images:\n","        masks_per_image = []\n","        predictor = SamPredictor(sam)\n","        predictor.set_image(image)\n","\n","        for point in grid_points:\n","            x, y = point\n","            input_point = np.array([[x, y]])\n","            input_label = np.array([1])\n","\n","            # Perform prediction for the predictor\n","            masks, scores, logits = predictor.predict(\n","                point_coords=input_point,\n","                point_labels=input_label,\n","                multimask_output=True,\n","            )\n","\n","            # Select the mask with highest score\n","            mask = masks[np.argmax(scores)]\n","            masks_per_image.append(mask)\n","\n","\n","        output_masks.append(masks_per_image)\n","\n","    return output_masks"]},{"cell_type":"code","execution_count":null,"id":"-hNOTCS1Q_k7","metadata":{"id":"-hNOTCS1Q_k7"},"outputs":[],"source":["grid = create_grid(images[0].shape[1], images[0].shape[0], 10)\n","output_masks = predict_masks_at_grid_points(images, grid)"]},{"cell_type":"code","execution_count":null,"id":"V-XUE2z7UcbJ","metadata":{"id":"V-XUE2z7UcbJ"},"outputs":[],"source":["binary_output_masks = []\n","\n","for masks_per_image in output_masks:\n","    binary_masks_per_image = []\n","    for mask in masks_per_image:\n","        binary_mask = mask.astype(int)\n","        binary_masks_per_image.append(binary_mask)\n","    binary_output_masks.append(binary_masks_per_image)"]},{"cell_type":"markdown","id":"tJpFfIOi0Ozi","metadata":{"id":"tJpFfIOi0Ozi"},"source":["# Results"]},{"cell_type":"code","execution_count":null,"id":"zpCRymSxdMSH","metadata":{"id":"zpCRymSxdMSH"},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score, precision_score\n","import numpy as np\n","\n","def compute_metrics(reference_mask_flat, mask_flat):\n","    # Compute metrics\n","    f1 = f1_score(reference_mask_flat, mask_flat)\n","    accuracy = accuracy_score(reference_mask_flat, mask_flat)\n","    precision = precision_score(reference_mask_flat, mask_flat)\n","\n","    # Intersection over Union (IoU)\n","    intersection = np.logical_and(reference_mask_flat, mask_flat)\n","    union = np.logical_or(reference_mask_flat, mask_flat)\n","    iou = np.sum(intersection) / np.sum(union)\n","\n","    return f1, accuracy, precision, iou\n","\n","def find_best_mask(reference_mask_flat, masks):\n","    best_metrics = {'f1': 0, 'accuracy': 0, 'precision': 0, 'iou': 0}\n","    best_mask = None\n","\n","    for idx, mask in enumerate(masks):\n","        mask_flat = mask.flatten()\n","        f1, accuracy, precision, iou = compute_metrics(reference_mask_flat, mask_flat)\n","\n","        # Update best metrics if current metrics are better\n","        if f1 > best_metrics['f1']:\n","            best_metrics['f1'] = f1\n","            best_metrics['accuracy'] = accuracy\n","            best_metrics['precision'] = precision\n","            best_metrics['iou'] = iou\n","            best_mask = mask\n","            best_index = idx\n","\n","    return best_metrics, best_mask, best_index"]},{"cell_type":"code","execution_count":null,"id":"ddeb7ysmZj3U","metadata":{"id":"ddeb7ysmZj3U"},"outputs":[],"source":["reference_mask_flat = raster_reference.flatten()\n","best_metrics_per_image = []\n","best_masks_per_image = []\n","best_index_per_image = [] # index of the position in the list of the best mask -> we need it to keep track of what point coordinates we are considering\n","\n","# Iterate over each image's masks\n","for masks_per_image in binary_output_masks:\n","    best_metrics, best_mask, best_index = find_best_mask(reference_mask_flat, masks_per_image)\n","    best_metrics_per_image.append(best_metrics)\n","    best_masks_per_image.append(best_mask)\n","    best_index_per_image.append(best_index)"]},{"cell_type":"code","execution_count":null,"id":"CakhjLepmg3z","metadata":{"id":"CakhjLepmg3z"},"outputs":[],"source":["n_images = len(images)\n","fig, axs = plt.subplots(n_images, figsize=(20, 20))\n","\n","# Print the best metrics for each image and plot the corresponding mask\n","for idx, best_metrics in enumerate(best_metrics_per_image):\n","\n","    # Plotting\n","    ax = axs[idx]\n","    ax.imshow(images[idx])\n","    ax.axis('off')\n","    ax.set_title(f'Image {idx}')\n","    coordinates = np.array([grid[best_index_per_image[idx]]]) # Change the name of the grid\n","    show_mask(best_masks_per_image[idx], ax, random_color=True)\n","    show_points(coordinates, np.array([1]), ax, marker_size=100)\n","\n","\n","    # Printing (4 significant digits)\n","    print(f\"Best Metrics for Image {idx}:\")\n","    print(f\"F1 Score: {best_metrics['f1']:.4f}\")\n","    print(f\"Accuracy: {best_metrics['accuracy']:.4f}\")\n","    print(f\"Precision: {best_metrics['precision']:.4f}\")\n","    print(f\"IoU: {best_metrics['iou']:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"id":"JApgrPtrqjrN","metadata":{"id":"JApgrPtrqjrN"},"outputs":[],"source":["def plot_metrics_on_image(ax, image, reference, mask):\n","    # Compute TP, TN, FP, FN\n","    TP = np.logical_and(mask, reference)\n","    TN = np.logical_and(np.logical_not(mask), np.logical_not(reference))\n","    FP = np.logical_and(mask, np.logical_not(reference))\n","    FN = np.logical_and(np.logical_not(mask), reference)\n","\n","    # Create a copy of the original image\n","    img_with_metrics = np.copy(image)\n","\n","    # Define colors for TP, TN, FP, FN\n","    colors = {\n","        'TP': (0, 0, 255),  # Blue for True Positives\n","        'TN': (0, 255, 0),  # Green for True Negatives\n","        'FP': (255, 0, 0),  # Red for False Positives\n","        'FN': (255, 255, 0),  # Yellow for False Negatives\n","    }\n","\n","    # Overlay colors for TP, TN, FP, FN on the copied image\n","    img_with_metrics[TP] = colors['TP']\n","    img_with_metrics[TN] = colors['TN']\n","    img_with_metrics[FP] = colors['FP']\n","    img_with_metrics[FN] = colors['FN']\n","\n","    # Display the image\n","    ax.imshow(img_with_metrics)\n","    ax.axis('off')"]},{"cell_type":"code","execution_count":null,"id":"jVhMR_giqnJV","metadata":{"id":"jVhMR_giqnJV"},"outputs":[],"source":["# Plot of the metrics\n","\n","n_images = len(best_masks_per_image)\n","fig, axs = plt.subplots(1, n_images, figsize=(20, 5))\n","\n","# Loop through each image and its corresponding mask\n","for idx, (mask, ax) in enumerate(zip(best_masks_per_image, axs)):\n","    plot_metrics_on_image(ax, images[idx], raster_reference, mask)\n","    ax.set_title(f'Image {idx}')  # Add title to each subplot\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"66A2LfJM6XsG","metadata":{"id":"66A2LfJM6XsG"},"source":["# 2D map of F1 score"]},{"cell_type":"code","execution_count":null,"id":"7gHkkZvs-MxY","metadata":{"id":"7gHkkZvs-MxY"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","f1_scores_periods = []\n","reference_mask_flat = raster_reference.flatten()\n","for mask_periods in binary_output_masks:\n","  f1_scores = []\n","  f1_scores_periods.append(f1_scores)\n","  for mask in mask_periods:\n","    mask = mask.flatten()\n","    f1_scores.append(f1_score(reference_mask_flat, mask))"]},{"cell_type":"code","execution_count":null,"id":"UADi4z2x6bMj","metadata":{"id":"UADi4z2x6bMj"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from scipy.interpolate import griddata\n","from matplotlib.colors import LogNorm\n","\n","def interpolate_f1_score_map(grid, f1_scores, image_shape):\n","    # Create grid points and corresponding F1 scores\n","    grid_x = np.array([point[0] for point in grid])\n","    grid_y = np.array([point[1] for point in grid])\n","\n","    # Generate coordinates for the entire image\n","    x_new = np.arange(image_shape[1])\n","    y_new = np.arange(image_shape[0])\n","    xx, yy = np.meshgrid(x_new, y_new)\n","\n","    # Interpolate F1 scores for the entire image using linear interpolation\n","    f1_score_map = griddata((grid_x, grid_y), f1_scores, (xx, yy), method='linear', fill_value=np.nan)\n","\n","    # Use nearest interpolation to fill in the NaN values resulting from the linear interpolation\n","    nan_mask = np.isnan(f1_score_map)\n","    f1_score_map[nan_mask] = griddata((grid_x, grid_y), f1_scores, (xx, yy), method='nearest', fill_value=np.nan)[nan_mask]\n","\n","    return f1_score_map\n","\n","\n","\n","# Plot the map\n","def visualize_f1_score_maps(f1_score_maps):\n","\n","    fig, axes = plt.subplots(1,4, figsize=(15, 5))\n","    axes = axes.ravel()  # Flatten the 2D array of axes to a 1D array for easy iteration\n","\n","    for idx, (ax, f1_score_map) in enumerate(zip(axes, f1_score_maps)):\n","        im = ax.imshow(f1_score_map, cmap='viridis', interpolation='nearest')\n","        coordinates = np.array([grid[best_index_per_image[idx]]]) # Change the name of the grid\n","        show_points(coordinates, np.array([1]), ax, marker_size=100)\n","        ax.set_title(f'F1 Score Map {idx}')\n","        ax.set_xlabel('Grid Column')\n","        ax.set_ylabel('Grid Row')\n","\n","    # Create a dedicated axis for the colorbar\n","    cbar_ax = fig.add_axes([0.92, 0.3, 0.02, 0.5])  # [left, bottom, width, height]\n","    fig.colorbar(im, cax=cbar_ax, label='F1 Score')\n","    fig.suptitle('VV+VH+VV/VH (all filtered) - Genova harbour area', fontsize=16)\n","\n","    plt.tight_layout(rect=[0, 0, 0.9, 1])  # Adjust layout to make space for colorbar\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"-5x_0TSj1LkB","metadata":{"id":"-5x_0TSj1LkB"},"outputs":[],"source":["image_shape = binary_output_masks[0][0].shape\n","f1_maps = []\n","for scores in f1_scores_periods:\n","  f1_map = interpolate_f1_score_map(grid, scores, image_shape)\n","  f1_maps.append(f1_map)"]},{"cell_type":"code","execution_count":null,"id":"I5ftHJG7MHO_","metadata":{"id":"I5ftHJG7MHO_"},"outputs":[],"source":["visualize_f1_score_maps(f1_maps)"]},{"cell_type":"markdown","id":"IcFnyp5SkreI","metadata":{"id":"IcFnyp5SkreI"},"source":["# Comparison with AWEI+Otsu masks"]},{"cell_type":"code","execution_count":null,"id":"LnyA98aPk1el","metadata":{"id":"LnyA98aPk1el"},"outputs":[],"source":["reference_mask_flat = raster_reference.flatten()\n","\n","metrics = []\n","for image in images:\n","  f1, accuracy, precision, iou = compute_metrics(reference_mask_flat, image.flat)\n","  metrics_dict = {'f1': f1, 'accuracy': accuracy, 'precision': precision, 'iou': iou}\n","  metrics.append(metrics_dict)"]},{"cell_type":"code","execution_count":null,"id":"-33sVp7tmFFS","metadata":{"id":"-33sVp7tmFFS"},"outputs":[],"source":[" # Printing (4 significant digits)\n"," for idx in range(4):\n","  metrics_image = metrics[idx]\n","  print(f\"Metrics for Image {idx}:\")\n","  print(f\"Accuracy: {metrics_image['accuracy']:.4f}\")\n","  print(f\"Precision: {metrics_image['precision']:.4f}\")\n","  print(f\"F1 Score: {metrics_image['f1']:.4f}\")\n","  print(f\"IoU: {metrics_image['iou']:.4f}\")\n","  print()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["c0b71431","M67jQRf-3xXg","g9EXPR7SfQ1K","_MLjm669-Z_L","kdXpxWFzpdp1","MDLj0W8waNvn","tJpFfIOi0Ozi","66A2LfJM6XsG","IcFnyp5SkreI"],"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"https://github.com/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb","timestamp":1681556634627}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":5}